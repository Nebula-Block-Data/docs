
# Overview
Welcome to Nebula Block's Dedicated Endpoints for AI Inference, the ultimate solution for users requiring custom 
infrastructure and model configurations. With dedicated endpoints, you can deploy pre-existing models like 
Meta LLaMA and Qwen or upload your own custom models on hardware you choose.

To use this product, please get in touch with us [here](https://www.nebulablock.com/contact). 

## Key Features
- **Customizable Hardware:** Select the GPU and memory configuration to meet your needs.
- **Deploy Any Model:** Use Nebula Block's pre-trained LLMs or upload your custom models.
- **Full Control:** Fine-tune deployment settings for optimal performance.
- **Scalability:** Designed to handle demanding workloads with dedicated resources.

## Prerequisites
- **Nebula Block Account:** Ensure you have an account on the [Nebula Block](https://nebula-block.com).
- **Credit Balance:** Ensure you have a sufficient credit balance in your account to start a GPU instance 
for at least an hour.

## Pricing and Billing
- **Pay-As-You-Go:** Billing is based on the selected hardware and duration of use.
- Check the [pricing page](https://nebula-block.com/pricing) for details.